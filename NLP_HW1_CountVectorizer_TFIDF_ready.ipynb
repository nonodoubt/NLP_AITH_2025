{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Импорты и переменные"
      ],
      "metadata": {
        "id": "ca5xsKpzrENH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install corus\n",
        "!pip install pymorphy3\n",
        "!wget https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz\n",
        "\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import re\n",
        "import pymorphy3\n",
        "from nltk.corpus import stopwords\n",
        "from corus import load_lenta\n",
        "\n",
        "# Загружаем стоп-слова\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('russian'))\n",
        "\n",
        "# Загружаем данные\n",
        "path = 'lenta-ru-news.csv.gz'\n",
        "records = load_lenta(path)\n",
        "\n",
        "max_samples = 100000 # обрежем датасет до 100000 записей"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvLl6WvJ_17G",
        "outputId": "85099386-07e9-40f9-8741-5d3d8413773d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: corus in /usr/local/lib/python3.11/dist-packages (0.10.0)\n",
            "Requirement already satisfied: pymorphy3 in /usr/local/lib/python3.11/dist-packages (2.0.3)\n",
            "Requirement already satisfied: dawg2-python>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from pymorphy3) (0.9.0)\n",
            "Requirement already satisfied: pymorphy3-dicts-ru in /usr/local/lib/python3.11/dist-packages (from pymorphy3) (2.4.417150.4580142)\n",
            "--2025-03-04 19:41:41--  https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250304%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250304T194142Z&X-Amz-Expires=300&X-Amz-Signature=2cb22332f8cf93b71e198c6bba2223862e2fb9c42f4f0fcd02c9cc89b0b73972&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-03-04 19:41:42--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250304%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250304T194142Z&X-Amz-Expires=300&X-Amz-Signature=2cb22332f8cf93b71e198c6bba2223862e2fb9c42f4f0fcd02c9cc89b0b73972&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 527373240 (503M) [application/octet-stream]\n",
            "Saving to: ‘lenta-ru-news.csv.gz.12’\n",
            "\n",
            "lenta-ru-news.csv.g 100%[===================>] 502.94M  19.0MB/s    in 13s     \n",
            "\n",
            "2025-03-04 19:41:55 (38.2 MB/s) - ‘lenta-ru-news.csv.gz.12’ saved [527373240/527373240]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Лемматизация и предобработка текста"
      ],
      "metadata": {
        "id": "PZAbWelarLW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "morph = pymorphy3.MorphAnalyzer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Приводим к нижнему регистру\n",
        "    text = re.sub(r'\\d+', '', text)  # Убираем числа\n",
        "    text = re.sub(r'[^а-яА-Яa-zA-Z\\s]', '', text)  # Убираем знаки препинания\n",
        "    words = text.split()  # Токенизация\n",
        "    words = [morph.parse(word)[0].normal_form for word in words if word not in stop_words]  # Лемматизация\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Преобразуем записи в DataFrame\n",
        "data = []\n",
        "for record in tqdm(records, desc=\"Загрузка данных\"):\n",
        "    data.append({\n",
        "        \"title\": record.title,\n",
        "        \"text\": record.text,\n",
        "        \"topic\": record.topic.strip()  # Убираем лишние пробелы\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Фильтрация классов: удаляем те, где менее 100 объектов класса\n",
        "class_counts = df['topic'].value_counts()\n",
        "print(f\"Число строк до фильтрации: {len(df)}\")\n",
        "print(df['topic'].value_counts())\n",
        "valid_classes = class_counts[class_counts >= 100].index\n",
        "df_filtered = df[df['topic'].isin(valid_classes)]\n",
        "print()\n",
        "# Ограничиваем размер выборки до 100000\n",
        "if len(df_filtered) > max_samples:\n",
        "    df_filtered = df_filtered.sample(n=max_samples, random_state=42)\n",
        "\n",
        "# После выборки проверяем классы заново\n",
        "class_counts_after = df_filtered['topic'].value_counts()\n",
        "valid_classes_after = class_counts_after[class_counts_after >= 100].index\n",
        "df_final = df_filtered[df_filtered['topic'].isin(valid_classes_after)]\n",
        "\n",
        "# Если после фильтрации строк стало меньше 10,000 — дополняем их из самых популярных тем\n",
        "if len(df_final) < max_samples:\n",
        "    remaining_samples = max_samples - len(df_final)\n",
        "    most_common_topic = df_filtered['topic'].value_counts().idxmax()\n",
        "    additional_samples = df_filtered[df_filtered['topic'] == most_common_topic].sample(n=remaining_samples, random_state=42)\n",
        "    df_final = pd.concat([df_final, additional_samples])\n",
        "\n",
        "# Итоговый датасет\n",
        "print(f\"Число строк после финальной фильтрации: {len(df_final)}\")\n",
        "print(df_final['topic'].value_counts())\n",
        "\n",
        "# Применяем предобработку текста\n",
        "tqdm.pandas(desc=\"Предобработка текста\")\n",
        "df_final['processed_text'] = df_final['text'].progress_apply(preprocess_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1J8HGjrr1Pt",
        "outputId": "a35758be-5e3f-474b-db11-da3199091824"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Загрузка данных: 739351it [01:19, 9284.72it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Число строк до фильтрации: 739351\n",
            "topic\n",
            "Россия               160519\n",
            "Мир                  136680\n",
            "Экономика             79538\n",
            "Спорт                 64421\n",
            "Культура              53803\n",
            "Бывший СССР           53402\n",
            "Наука и техника       53136\n",
            "Интернет и СМИ        44675\n",
            "Из жизни              27611\n",
            "Дом                   21734\n",
            "Силовые структуры     19596\n",
            "Ценности               7766\n",
            "Бизнес                 7399\n",
            "Путешествия            6408\n",
            "69-я параллель         1268\n",
            "Крым                    666\n",
            "Культпросвет            340\n",
            "                        203\n",
            "Легпром                 114\n",
            "Библиотека               65\n",
            "Оружие                    3\n",
            "ЧМ-2014                   2\n",
            "МедНовости                1\n",
            "Сочи                      1\n",
            "Name: count, dtype: int64\n",
            "Число строк после финальной фильтрации: 100000\n",
            "topic\n",
            "Россия               22080\n",
            "Мир                  18403\n",
            "Экономика            10838\n",
            "Спорт                 8819\n",
            "Культура              7248\n",
            "Наука и техника       7229\n",
            "Бывший СССР           7120\n",
            "Интернет и СМИ        5965\n",
            "Из жизни              3741\n",
            "Дом                   2948\n",
            "Силовые структуры     2570\n",
            "Ценности              1020\n",
            "Бизнес                 988\n",
            "Путешествия            854\n",
            "69-я параллель         177\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Предобработка текста: 100%|██████████| 100000/100000 [31:20<00:00, 53.18it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подготовка выборок"
      ],
      "metadata": {
        "id": "dljfVnPhtCvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_final['processed_text']\n",
        "y = df_final['topic']\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, stratify=y, random_state=222)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=222)"
      ],
      "metadata": {
        "id": "q1x_ViPFr_5i"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Векторизация корпуса текстов"
      ],
      "metadata": {
        "id": "OC9YE8oBsFuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "X_train_count = count_vectorizer.fit_transform(X_train)\n",
        "X_val_count = count_vectorizer.transform(X_val)\n",
        "X_test_count = count_vectorizer.transform(X_test)\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_val_tfidf = tfidf_vectorizer.transform(X_val)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "pPTOxQImsIVM"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение моделей, подбор гиперпараметров"
      ],
      "metadata": {
        "id": "BASRgttrtLeB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучение моделей и подбор гиперпараметров производится на 3 вариантах:\n",
        "\n",
        "* Наивный байесовсикй классификатор MultinomialNB для countvectorizer\n",
        "* Логистическая регрессия для countvectorizer + gridsearch\n",
        "* Логистическая регрессия для TF-IDF + gridsearch\n",
        "\n",
        "Сравнение результатов моделей производится на отложенной валидационной выборке.\n",
        "\n",
        "Итоговый тест выполнен для лучшей модели"
      ],
      "metadata": {
        "id": "_p0yo6i-1mqD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MultinomialNB"
      ],
      "metadata": {
        "id": "U0kVnU4rz5qm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Наивный байесовский классификаторхорошо работает для задач текстовой классификации, особенно при использовании векторизации через CountVectorizer или TfidfVectorizer. Dummy_classifier не справляется совсем\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train_count, y_train)\n",
        "y_pred_nb = nb_classifier.predict(X_val_count)\n",
        "print(\"Результаты для MultinomialNB + CountVectorizer:\")\n",
        "print(classification_report(y_val, y_pred_nb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kq71cXoPsQi3",
        "outputId": "4d08e514-4ace-4eb8-ad1f-c3d0e545268f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результаты для MultinomialNB + CountVectorizer:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   69-я параллель       0.00      0.00      0.00        36\n",
            "           Бизнес       0.40      0.01      0.02       198\n",
            "      Бывший СССР       0.78      0.74      0.76      1424\n",
            "              Дом       0.85      0.65      0.74       589\n",
            "         Из жизни       0.67      0.49      0.57       748\n",
            "   Интернет и СМИ       0.72      0.61      0.66      1193\n",
            "         Культура       0.82      0.85      0.83      1449\n",
            "              Мир       0.76      0.85      0.81      3680\n",
            "  Наука и техника       0.79      0.84      0.81      1446\n",
            "      Путешествия       1.00      0.06      0.12       171\n",
            "           Россия       0.72      0.82      0.77      4416\n",
            "Силовые структуры       0.57      0.10      0.17       514\n",
            "            Спорт       0.96      0.94      0.95      1764\n",
            "         Ценности       0.98      0.56      0.72       204\n",
            "        Экономика       0.75      0.89      0.82      2168\n",
            "\n",
            "         accuracy                           0.77     20000\n",
            "        macro avg       0.72      0.56      0.58     20000\n",
            "     weighted avg       0.77      0.77      0.76     20000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression с CountVectorizer"
      ],
      "metadata": {
        "id": "9REnZs260As3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_count = LogisticRegression(random_state=222)\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],  # Параметр регуляризации\n",
        "    'max_iter': [100, 200, 300],  # Число итераций\n",
        "    'solver': ['liblinear']  # Алгоритмы оптимизации\n",
        "}\n",
        "\n",
        "grid_search_count = GridSearchCV(estimator=lr_count, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
        "grid_search_count.fit(X_train_count, y_train)\n",
        "\n",
        "# Лучшая модель для CountVectorizer\n",
        "best_lr_count = grid_search_count.best_estimator_\n",
        "\n",
        "# Оценка модели на валидационной выборке с CountVectorizer\n",
        "y_pred_val_count = best_lr_count.predict(X_val_count)\n",
        "print(\"Результаты для Logistic Regression + CountVectorizer:\")\n",
        "print(classification_report(y_val, y_pred_val_count))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCY1mV56sQcx",
        "outputId": "833d3d5c-9e11-4e38-a001-2b50a21ed210"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "Результаты для Logistic Regression + CountVectorizer:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   69-я параллель       0.78      0.19      0.31        36\n",
            "           Бизнес       0.58      0.26      0.36       198\n",
            "      Бывший СССР       0.84      0.80      0.82      1424\n",
            "              Дом       0.84      0.79      0.81       589\n",
            "         Из жизни       0.65      0.56      0.60       748\n",
            "   Интернет и СМИ       0.76      0.71      0.73      1193\n",
            "         Культура       0.86      0.88      0.87      1449\n",
            "              Мир       0.79      0.84      0.81      3680\n",
            "  Наука и техника       0.84      0.82      0.83      1446\n",
            "      Путешествия       0.84      0.54      0.65       171\n",
            "           Россия       0.77      0.84      0.80      4416\n",
            "Силовые структуры       0.68      0.43      0.53       514\n",
            "            Спорт       0.96      0.96      0.96      1764\n",
            "         Ценности       0.92      0.83      0.87       204\n",
            "        Экономика       0.82      0.85      0.84      2168\n",
            "\n",
            "         accuracy                           0.81     20000\n",
            "        macro avg       0.80      0.69      0.72     20000\n",
            "     weighted avg       0.81      0.81      0.81     20000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression с TfidfVectorizer"
      ],
      "metadata": {
        "id": "4IigHHD40Eq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_tfidf = LogisticRegression(random_state=222)\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],  # Параметр регуляризации\n",
        "    'max_iter': [100, 200, 300],  # Число итераций\n",
        "    'solver': ['liblinear']  # Алгоритмы оптимизации\n",
        "}\n",
        "\n",
        "\n",
        "grid_search_tfidf = GridSearchCV(estimator=lr_tfidf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
        "grid_search_tfidf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Лучшая модель для TfidfVectorizer\n",
        "best_lr_tfidf = grid_search_tfidf.best_estimator_\n",
        "\n",
        "# Оценка модели на валидационной выборке с TfidfVectorizer\n",
        "y_pred_val_tfidf = best_lr_tfidf.predict(X_val_tfidf)\n",
        "print(\"Результаты для Logistic Regression + TfidfVectorizer:\")\n",
        "print(classification_report(y_val, y_pred_val_tfidf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2D-aqbv1sQV1",
        "outputId": "4b9e1c8e-0ba7-4958-91b5-54e55d2e95ac"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "Результаты для Logistic Regression + TfidfVectorizer:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   69-я параллель       0.86      0.17      0.28        36\n",
            "           Бизнес       0.68      0.24      0.36       198\n",
            "      Бывший СССР       0.84      0.83      0.83      1424\n",
            "              Дом       0.85      0.79      0.82       589\n",
            "         Из жизни       0.68      0.57      0.62       748\n",
            "   Интернет и СМИ       0.77      0.71      0.74      1193\n",
            "         Культура       0.86      0.90      0.88      1449\n",
            "              Мир       0.79      0.85      0.82      3680\n",
            "  Наука и техника       0.83      0.85      0.84      1446\n",
            "      Путешествия       0.83      0.53      0.65       171\n",
            "           Россия       0.79      0.84      0.81      4416\n",
            "Силовые структуры       0.69      0.41      0.52       514\n",
            "            Спорт       0.96      0.96      0.96      1764\n",
            "         Ценности       0.89      0.82      0.85       204\n",
            "        Экономика       0.83      0.86      0.85      2168\n",
            "\n",
            "         accuracy                           0.82     20000\n",
            "        macro avg       0.81      0.69      0.72     20000\n",
            "     weighted avg       0.82      0.82      0.81     20000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Сравнение результатов моделей"
      ],
      "metadata": {
        "id": "2mV8R-iRsgHy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAi39Qt83-fA"
      },
      "outputs": [],
      "source": [
        "# Валидация происходит на отложенной валидационной выборке\n",
        "# Сравниваем результаты для трех моделей\n",
        "print(\"Сравнение моделей по результатам на валидационной выборке:\")\n",
        "print(\"MultinomialNB: \\n\", classification_report(y_val, y_pred_nb))\n",
        "print()\n",
        "print(\"Logistic Regression + CountVectorizer: \\n\", classification_report(y_val, y_pred_val_count))\n",
        "print()\n",
        "print(\"Logistic Regression + TfidfVectorizer: \\n\", classification_report(y_val, y_pred_val_tfidf))\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Финальное тестирование"
      ],
      "metadata": {
        "id": "7kWa5F8nsoRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Лучашя модель по результатам: TF-IDF:\n",
        "print(\"Лучшая модель: Logistic Regression + CountVectorizer\")\n",
        "best_model = best_lr_tfidf\n",
        "y_pred_test = best_lr_tfidf.predict(X_test_tfidf)\n",
        "print(\"\\n Результаты: \\n \\n\", classification_report(y_test, y_pred_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Do7utM2psnSY",
        "outputId": "fec3f567-6605-4a35-d38a-2600f6079ecd"
      },
      "execution_count": 64,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Лучшая модель: Logistic Regression + CountVectorizer\n",
            "\n",
            " Результаты: \n",
            " \n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "   69-я параллель       0.92      0.31      0.47        35\n",
            "           Бизнес       0.65      0.28      0.40       197\n",
            "      Бывший СССР       0.83      0.82      0.83      1424\n",
            "              Дом       0.87      0.82      0.84       590\n",
            "         Из жизни       0.69      0.58      0.63       748\n",
            "   Интернет и СМИ       0.78      0.72      0.75      1193\n",
            "         Культура       0.89      0.90      0.89      1450\n",
            "              Мир       0.80      0.85      0.82      3681\n",
            "  Наука и техника       0.83      0.85      0.84      1446\n",
            "      Путешествия       0.80      0.61      0.70       171\n",
            "           Россия       0.78      0.83      0.81      4416\n",
            "Силовые структуры       0.65      0.39      0.49       514\n",
            "            Спорт       0.96      0.98      0.97      1764\n",
            "         Ценности       0.93      0.79      0.85       204\n",
            "        Экономика       0.85      0.87      0.86      2167\n",
            "\n",
            "         accuracy                           0.82     20000\n",
            "        macro avg       0.81      0.71      0.74     20000\n",
            "     weighted avg       0.82      0.82      0.82     20000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Вывод\n",
        "\n",
        "* Произведена подготовка датасета, включающая в себя очистку, лемматизацию, привдение к единообразию, токенизацию.\n",
        "* Корпус текстов собран в датасет. Датасет разделен на тренеровочную, валидационную и тестовую выборки. Выборки созданы с учетом стратификации, редкие темы (меньше 65 объектов) отсеяны.\n",
        "* Для моделей произведено обучение и валидирование результатов\n",
        "* Лучшая модель протестирована на отложенной тестовой выборке.\n",
        "* Лучшие результаты показала модель логистической регрессии + TF-IDF с результатом метрики accuracy, равно 0.82 при обучении на корпусе 100 000 строк."
      ],
      "metadata": {
        "id": "zm1ugcO42rvx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PlnPhOL9H6UX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}